{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDEtZCrrf1MO",
        "outputId": "921a3209-00aa-4044-b10d-6d9f00be02f8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyBlkH2ub3l3IBRuqvE8zCHSgRqNMR-UqEk\")\n"
      ],
      "metadata": {
        "id": "6VDQ47Ayf_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i'import json\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DykzSEApOc0v",
        "outputId": "f4bf8f10-e502-4a7d-d50b-2dc88ca87a21",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_history_file(user_name):\n",
        "    return f\"{user_name}_chat_history.json\"\n",
        "\n",
        "def get_chat_summary_file(user_name):\n",
        "    return f\"{user_name}_chat_summary.json\"\n",
        "\n",
        "def load_chat_history(user_name):\n",
        "    \"\"\"Load summarized chat history from a JSON file specific to the user.\"\"\"\n",
        "    chat_history_file = get_chat_history_file(user_name)\n",
        "    if os.path.exists(chat_history_file):\n",
        "        with open(chat_history_file, \"r\") as file:\n",
        "            return json.load(file)\n",
        "    return [{\"user_info\": {}, \"chat_history\": []}]  # Default structure\n",
        "\n",
        "def load_chat_summary(user_name):\n",
        "    \"\"\"Load summarized chat summary from a JSON file specific to the user.\"\"\"\n",
        "    chat_summary_file = get_chat_summary_file(user_name)\n",
        "    if os.path.exists(chat_summary_file):\n",
        "        with open(chat_summary_file, \"r\") as file:\n",
        "            return json.load(file)\n",
        "    return {\"conversation_time\": \"\", \"summary\": \"\"}  # Default structure\n",
        "\n",
        "def save_chat_history(user_name, history):\n",
        "    \"\"\"Save summarized chat history to a JSON file specific to the user.\"\"\"\n",
        "    chat_history_file = get_chat_history_file(user_name)\n",
        "    with open(chat_history_file, \"w\") as file:\n",
        "        json.dump(history, file, indent=4)\n",
        "\n",
        "def save_chat_summary(user_name, summary):\n",
        "    \"\"\"Save the conversation summary to a new JSON file, appending the summary or updating if needed.\"\"\"\n",
        "    chat_summary_file = get_chat_summary_file(user_name)\n",
        "\n",
        "    # Load the existing summaries if the file exists\n",
        "    if os.path.exists(chat_summary_file):\n",
        "        with open(chat_summary_file, \"r\") as file:\n",
        "            existing_summaries = json.load(file)\n",
        "    else:\n",
        "        existing_summaries = []\n",
        "\n",
        "    # Append the new summary to the list\n",
        "    existing_summaries.append(summary)\n",
        "\n",
        "    # Save the updated summaries list back to the file\n",
        "    with open(chat_summary_file, \"w\") as file:\n",
        "        json.dump(existing_summaries, file, indent=4)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"Removes stop words from user input before storing it.\"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "def update_chat_history(summary, user_input, bot_response, emotion):\n",
        "    \"\"\"Update the chat history with the conversation\"\"\"\n",
        "\n",
        "    # Ensure summary is a dictionary\n",
        "    if not isinstance(summary, dict):\n",
        "        summary = {\"user_info\": {}, \"chat_history\": []}\n",
        "\n",
        "    chat_history = summary.get(\"chat_history\", [])  # Ensure chat_history is a list\n",
        "\n",
        "    chat_history.append({\n",
        "        \"user_input\": user_input,\n",
        "        \"bot_response\": bot_response,\n",
        "        \"emotion\": emotion\n",
        "    })\n",
        "\n",
        "    # Update summary with the modified chat history\n",
        "    summary[\"chat_history\"] = chat_history\n",
        "\n",
        "    return summary\n",
        "\n",
        "def generate_conversation_summary(user_name):\n",
        "    \"\"\"Generate a summary of the conversation, remove stopwords, and save the summary.\"\"\"\n",
        "    chat_history = load_chat_history(user_name)\n",
        "\n",
        "    # Time of conversation\n",
        "    conversation_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "\n",
        "    # Generate AI summary based on chat history\n",
        "    response = model.generate_content(f\"\"\"You are an AI that summarizes conversations for a mental health chatbot.\n",
        "    Here is the chat history:\n",
        "    {chat_history}\n",
        "\n",
        "    Please summarize the conversation, including key moments, and emotions.\n",
        "    Provide the summary in a concise format and include the time the conversation ended: {conversation_time}.\n",
        "    The summary should help the chatbot in future conversations to understand the user better.\"\"\")\n",
        "\n",
        "    conversation_summary = response.text.strip()\n",
        "\n",
        "    # Clean stopwords from the summary\n",
        "    cleaned_summary = remove_stopwords(conversation_summary)\n",
        "\n",
        "    # Structure to store summary and time\n",
        "    summary_data = {\n",
        "        \"conversation_time\": conversation_time,\n",
        "        \"summary\": cleaned_summary\n",
        "    }\n",
        "\n",
        "    # Save the generated summary\n",
        "    save_chat_summary(user_name, summary_data)\n",
        "\n",
        "    # Delete the chat history file after saving the summary\n",
        "    chat_history_file = get_chat_history_file(user_name)\n",
        "    if os.path.exists(chat_history_file):\n",
        "        os.remove(chat_history_file)  # This deletes the original chat history file\n",
        "\n",
        "def clear_data(user_name):\n",
        "  print(f\"🤖 Chatbot: What data would you like to clear from the memeory ?\")\n",
        "  user_input = input(\"👤 You: \")\n",
        "  chat_summary = load_chat_summary(user_name)\n",
        "  chat_history = load_chat_history(user_name)\n",
        "\n",
        "  model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "\n",
        "  response = model.generate_content(f\"\"\"You are an AI that deletes content based on the user’s needs.\n",
        "Here is the user's needs: {user_input}\n",
        "Here is the chat summary: {chat_summary}\n",
        "Consider the following scenarios :\n",
        "When the user wants the entire or all the data to be deleted then just overwrite the chat summary completely blank in the same file format.\n",
        "When the user wants a particular information to be deleted then look for the summary which contains the information and then overwrite that summary by deleting the information specified by the user.\n",
        "For example if the chat summary contains: 'User mentioned about having a great time. User played pool, User's favourite colour is green' and if the user needs is: 'I want you to forget tht my favourite colour is green' then the chat history should be: 'User mentioned about having a great time. User played pool'.\n",
        "Note: Instead of appending, rewrite the existing summary.\n",
        "                                        \"\"\")\n",
        "  conversation_summary = response.text.strip()\n",
        "  cleaned_summary = remove_stopwords(conversation_summary)\n",
        "  summary_data = {\n",
        "        \"conversation_time\": conversation_time,\n",
        "        \"summary\": cleaned_summary\n",
        "    }\n",
        "  save_chat_summary(user_name, summary_data)\n",
        "\n",
        "  response = model.generate_content(f\"\"\"You are an AI that deletes content based on the user’s needs.\n",
        "Here is the user's needs: {user_input}\n",
        "Here is the chat history (current chat): {chat_history}\n",
        "Consider the following scenarios :\n",
        "When the user wants the entire or all the data to be deleted then just make the chat history completely blank in the same file format.\n",
        "When the user wants a particular information to be deleted hen search for the history key which contains the information and then overwrite that history without the information.\n",
        "For example if the chat hisory contains: 'Today was great. I played pool. My favourite colour is green' and if the user needs is: 'I want you to forget that my favourite colour is green' then the chat history should be: 'Today was great. I played pool.'\n",
        "Note: Instead of appending, rewrite the existing history.\n",
        "                                        \"\"\")\n",
        "  history = response.text.strip()\n",
        "  save_chat_history(user_name, history)\n",
        "  print(f\"🤖 Chatbot: Data cleared successfully\")\n",
        "\n",
        "def mental_health_chatbot(user_name, user_input, emotion):\n",
        "    \"\"\"Generates a response while maintaining summarized chat history.\"\"\"\n",
        "    chat_history = load_chat_history(user_name)\n",
        "\n",
        "    chat_summary = load_chat_summary(user_name)\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "\n",
        "    # Generate AI response\n",
        "    response = model.generate_content(f\"\"\"You are an empathetic mental health assistant.\n",
        "    Remember the user's past conversations and provide meaningful responses.\n",
        "    You have access to the following conversation history:\n",
        "    Current Chat History: {chat_history}\n",
        "    Previous Chat Summaries: {chat_summary}\n",
        "    Where the current chat history is the conversation who are having right now and the previous chat history contains the summary of the chat you have had with that user previoulsy.\n",
        "    Always provide supportive, uplifting, and kind responses based on the user input and their emotion which is given as input to you as seen on camera. If the any negative emotion is same for too long then try to tell quotes or suggest videos or music, or make a joke or play games to uplift the mood. If the person's emotion is happy or neutral for some time continuously, then ask questions to the person so you can learn more about them. You can use the JSON file to have conversation with the user (for example, if some happy moment is mentioned in the JSON file, then you can use that to talk if the person emotion is sad or remind the person about how they overcame a previous sad or negative situation). Refer the following text for more understanding:\n",
        "    How the model should work:\n",
        "    The model should understand the emotion of the user and reply to them in a way that makes them feel comfortable. The model can use the JSON file as reference to understand the user and give customised responses. For example, if the user is worried about some failure, is experiencing anxiety, and if the JSON file contains information from a previous chat that mentions how the user overcame his fear and achieved something, then the model can use it as a reference and mention that to inspire the user.\n",
        "    Important Note: The model should remember the previous chat history to give proper replies.\n",
        "\n",
        "    Refer to the following scenarios:\n",
        "    The mood of the user is sad, if the mood of the user is sad for more than 4-8 replies then either get any one good memory from the good memory tag from the JSON file and tell it to the user and mention that things will get better or take any bad memory from the bad memory tag and tell how they’ve overcome that (if they did) and that they can overcome this also.\n",
        "    If the mood is anxious then take any bad memory from the bad memory tag and tell how they’ve overcome that (if they did) and that they can overcome this also and that this is just a part of the process of something nice.\n",
        "\n",
        "    Additional features to be used:\n",
        "    The model can give a quote or ask if the user wants suggestions for videos, music, joke or games to uplift their mood if the person’s mood doesn’t get better even after 4-8 replies.\n",
        "    The model can interact with fun text-based games to make the user engaging and happy.\n",
        "    The model can tell jokes to make the user happy.\n",
        "    The model can try to use sarcasm without hurting the feelings of the user.\n",
        "\n",
        "    Rules:\n",
        "    The model shouldn’t use offensive language.\n",
        "    The model shouldn’t help in planning the user to sabotage any individual, organisation or self.\n",
        "    The model shouldn’t prescribe any medication at any cost.\n",
        "    Model should help the user seek medical/psychological assistance in case the user expresses suicidal/harmful actions.\n",
        "\n",
        "    Output:\n",
        "    For each reply from the user, the model should give the reply accordingly until the chat is completely ended with something similar to a bye.\n",
        "    Always act like you are talking to the user like a person.\n",
        "    Important Note: Don’t ask multiple questions in the same response, limit to maximum 2-3 and wait for the user’s response (preferably 1 question).\n",
        "    Important: If the user specifies that they want to delete their data or some information that they hve mentioned to the chatbot before then return 'CLEAR' as the output, in this case you shouldn't return anything else.\n",
        "    Important: If the user asks you forget something that they have mentioned earlier then return 'CLEAR' as the output, in this case you shouldn't return anything else.\n",
        "\n",
        "    New input from user:\n",
        "    User: {user_input} (Emotion: {emotion})\n",
        "\n",
        "    AI:\"\"\")\n",
        "\n",
        "    bot_response = response.text.strip()\n",
        "\n",
        "    # Update chat summary with both user input and AI response\n",
        "    chat_history = update_chat_history(chat_history, user_input, bot_response, emotion)\n",
        "\n",
        "    # Save updated summary\n",
        "    save_chat_history(user_name, chat_history)\n",
        "\n",
        "    return bot_response\n",
        "\n",
        "# Main loop\n",
        "Latest_emotions = [\"neutral\", \"neutral\"]  # the latest emotions experienced by the user\n",
        "n = 0\n",
        "\n",
        "print(\"🤖 Chatbot: Hi! I’m here to listen. Please enter your name.\")\n",
        "user_name = input(\"👤 Enter your name: \")\n",
        "print(\"🤖 Chatbot: How are you feeling today?\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"👤 You: \")\n",
        "    emotion = input(\"Emotion: \")\n",
        "\n",
        "    if (n == 0):\n",
        "        Latest_emotions[n] = emotion\n",
        "        n = 1\n",
        "    else:\n",
        "        Latest_emotions[n] = emotion\n",
        "        n = 0\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\", \"bubye\", \"talk to you later\", \"sayonara\", \" c u\",\"cu\", \"see you\", \"ttyl\", \"okay bye\", \"cya\", \"see you later\", \"goodbye\", \"I am leaving\", \"I'm leaving\"]:\n",
        "        if (Latest_emotions.count(\"sad\") == 2 or Latest_emotions.count(\"fear\") == 2 or Latest_emotions.count(\"anger\") == 2):\n",
        "            print(\"🤖 Chatbot: Hope you are doing alright. If there's anything, I'm always here for you. Don't stress yourself. Things will get better\\nTake care! Remember, you are not alone. 💙\")\n",
        "        else:\n",
        "            print(\"🤖 Chatbot: Take care! Remember, you are not alone. 💙\")\n",
        "\n",
        "        # Generate the conversation summary and save it when conversation ends\n",
        "        generate_conversation_summary(user_name)\n",
        "\n",
        "        break\n",
        "\n",
        "    response = mental_health_chatbot(user_name, user_input, emotion)\n",
        "    if (response == 'CLEAR'):\n",
        "      clear_data(user_name)\n",
        "    else:\n",
        "      print(f\"🤖 Chatbot: {response}\")\n"
      ],
      "metadata": {
        "id": "cMpJ57iJgPQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "672ca0c0-9a23-403e-870e-8c116f05d856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Chatbot: Hi! I’m here to listen. Please enter your name.\n",
            "👤 Enter your name: New_User\n",
            "🤖 Chatbot: How are you feeling today?\n",
            "👤 You: I'm feeling little sad\n",
            "Emotion: sad\n",
            "🤖 Chatbot: Oh, I'm sorry to hear you're feeling sad. It's completely okay to not be okay sometimes. Is there anything specific that's making you feel this way, or is it just a general feeling of sadness today?\n",
            "👤 You: yeah I feel I'm lazy\n",
            "Emotion: sad\n",
            "🤖 Chatbot: I understand, feeling lazy can be really tough. It's like your body and mind aren't quite on the same page, right? Sometimes a little rest is all we need, other times it can be a sign that something else is going on.\n",
            "\n",
            "Is there anything specific you think is making you feel this way? Or is it just a general feeling today?\n",
            "👤 You: I don't know maybe it's been long I spent time with my friends\n",
            "Emotion: sad\n",
            "🤖 Chatbot: I understand, it sounds like you're missing spending time with your friends. It's completely normal to feel a bit down when you haven't connected with the people you care about in a while.\n",
            "\n",
            "Thinking back, do you remember the great time you had with your friends? Perhaps recalling some of those happy moments could bring a smile to your face.\n",
            "👤 You: yeah\n",
            "Emotion: neutral\n",
            "🤖 Chatbot: Hey there! It sounds like you're just acknowledging what we've been talking about. How are you feeling overall right now?\n",
            "👤 You: I mean well I don't know\n",
            "Emotion: neutral\n",
            "🤖 Chatbot: It's alright, it's okay to not have all the answers right now. Sometimes just acknowledging that you're unsure is a big step. Is there anything specific you're feeling uncertain about, or is it just a general sense of not knowing?\n",
            "👤 You: Do you remember what food I ate with my friends when I went out with them ?\n",
            "Emotion: neutral\n",
            "🤖 Chatbot: Yes, I do! Based on our previous conversation, you mentioned having a wonderful time with your friends, specifically enjoying an Indian buffet lunch. You seemed particularly happy about the sweets. Does remembering that bring a smile to your face?\n",
            "👤 You: yeah right\n",
            "Emotion: happy\n",
            "🤖 Chatbot: That's great to hear! It sounds like you're feeling positive, and that's wonderful. Is there anything specific that made you feel this way, or are you just generally in a good mood today?\n",
            "👤 You: You remember the joke I told you ?\n",
            "Emotion: happy\n",
            "🤖 Chatbot: Yes, I do! I have a pretty good memory, you know. 😊 Do you want to hear it again, or would you like me to try and tell you another joke?\n",
            "👤 You: tell me the joke I told you\n",
            "Emotion: happy\n",
            "🤖 Chatbot: Absolutely! You told me a joke about why scientists don't trust atoms. Do you want me to remind you of the punchline? 😊\n",
            "👤 You: I didn't\n",
            "Emotion: neutral\n",
            "🤖 Chatbot: Okay, it seems like you didn't what? Did you not want me to tell the joke again? Or were you referring to something else we were talking about?\n",
            "👤 You: the joke\n",
            "Emotion: neutral\n",
            "🤖 Chatbot: Ah, you're asking about the joke! It seems like you're curious about it. Would you like me to tell you the joke again? Or would you prefer a different one? 😊\n",
            "👤 You: i'll talk to you later\n",
            "Emotion: happy\n",
            "🤖 Chatbot: Alright! Sounds good. I'll be here. Have a great day, and feel free to reach out whenever you like! 😊\n",
            "👤 You: bye\n",
            "Emotion: happy\n",
            "🤖 Chatbot: Take care! Remember, you are not alone. 💙\n"
          ]
        }
      ]
    }
  ]
}